{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "nlp8",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqzZj9OoE-dg",
        "outputId": "b76ea9be-9940-4459-bf68-7188f91ba347"
      },
      "source": [
        "!pip install stop_words\n",
        "!pip install pymorphy2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting stop_words\n",
            "  Downloading https://files.pythonhosted.org/packages/1c/cb/d58290804b7a4c5daa42abbbe2a93c477ae53e45541b1825e86f0dfaaf63/stop-words-2018.7.23.tar.gz\n",
            "Building wheels for collected packages: stop-words\n",
            "  Building wheel for stop-words (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for stop-words: filename=stop_words-2018.7.23-cp37-none-any.whl size=32917 sha256=eae43a305bb969ad98520653efff3e9e2b81f6fc3986cf2bab9aecb07f965d70\n",
            "  Stored in directory: /root/.cache/pip/wheels/75/37/6a/2b295e03bd07290f0da95c3adb9a74ba95fbc333aa8b0c7c78\n",
            "Successfully built stop-words\n",
            "Installing collected packages: stop-words\n",
            "Successfully installed stop-words-2018.7.23\n",
            "Collecting pymorphy2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/07/57/b2ff2fae3376d4f3c697b9886b64a54b476e1a332c67eee9f88e7f1ae8c9/pymorphy2-0.9.1-py3-none-any.whl (55kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 3.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: docopt>=0.6 in /usr/local/lib/python3.7/dist-packages (from pymorphy2) (0.6.2)\n",
            "Collecting dawg-python>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/84/ff1ce2071d4c650ec85745766c0047ccc3b5036f1d03559fd46bb38b5eeb/DAWG_Python-0.7.2-py2.py3-none-any.whl\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/79/bea0021eeb7eeefde22ef9e96badf174068a2dd20264b9a378f2be1cdd9e/pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2MB)\n",
            "\u001b[K     |████████████████████████████████| 8.2MB 7.4MB/s \n",
            "\u001b[?25hInstalling collected packages: dawg-python, pymorphy2-dicts-ru, pymorphy2\n",
            "Successfully installed dawg-python-0.7.2 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxZTAOJ9DhTR"
      },
      "source": [
        "# попробуем запрограммировать простую рекурентную сеть. Возьмем датасет с прошлого занятия\n",
        "\n",
        "import pandas as pd\n",
        "from string import punctuation\n",
        "from stop_words import get_stop_words\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "import re\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1a7keoZSH9dK"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv('data/twe.csv')\n",
        "data.head()\n",
        "X = data['tweet']\n",
        "y = data['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ3R2ulmE6nl"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0LLkGqMIVFP"
      },
      "source": [
        "df_train_dict = {'text':X_train.values, 'class':y_train.values}\n",
        "df_train = pd.DataFrame(df_train_dict)\n",
        "df_test_dict = {'text':X_test.values, 'class':y_test.values}\n",
        "df_test = pd.DataFrame(df_test_dict)\n",
        "df_val_dict = {'text':X_val.values, 'class':y_val.values}\n",
        "df_val = pd.DataFrame(df_val_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "HRKiPIemDhTS",
        "outputId": "6038d928-60fd-4fff-e3b7-28f5f7e6237f"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2night is the season finale of #livandmaddie o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>my day is officially ruined! builders have com...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i have my bed, food and netflix</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>after an hour of walking and looking for somet...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@user im not gonna lie i did think angela was...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  class\n",
              "0  2night is the season finale of #livandmaddie o...      0\n",
              "1  my day is officially ruined! builders have com...      0\n",
              "2                  i have my bed, food and netflix        0\n",
              "3  after an hour of walking and looking for somet...      0\n",
              "4   @user im not gonna lie i did think angela was...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VgVAHhz4DhTT"
      },
      "source": [
        "sw = set(get_stop_words(\"ru\"))\n",
        "exclude = set(punctuation)\n",
        "morpher = MorphAnalyzer()\n",
        "\n",
        "def preprocess_text(txt):\n",
        "    txt = str(txt)\n",
        "    txt = \"\".join(c for c in txt if c not in exclude)\n",
        "    txt = txt.lower()\n",
        "    txt = re.sub(\"\\sне\", \"не\", txt)\n",
        "    txt = [morpher.parse(word)[0].normal_form for word in txt.split() if word not in sw]\n",
        "    return \" \".join(txt)\n",
        "\n",
        "df_train['text'] = df_train['text'].apply(preprocess_text)\n",
        "df_val['text'] = df_val['text'].apply(preprocess_text)\n",
        "df_test['text'] = df_test['text'].apply(preprocess_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkfdFFKpDhTU"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D, SimpleRNN, LSTM, GRU, Masking\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import TensorBoard \n",
        "from keras.objectives import categorical_crossentropy\n",
        "from keras.callbacks import EarlyStopping  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bFQMvhHWDhTU"
      },
      "source": [
        "text_corpus_train = df_train['text'].values\n",
        "text_corpus_valid = df_val['text'].values\n",
        "text_corpus_test = df_test['text'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHmKCPQXDhTV"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=None, \n",
        "                     filters='#$%&()*+-<=>@[\\\\]^_`{|}~\\t\\n',\n",
        "                     lower = False, split = ' ')\n",
        "tokenizer.fit_on_texts(text_corpus_train)\n",
        "\n",
        "sequences_train = tokenizer.texts_to_sequences(text_corpus_train)\n",
        "sequences_val = tokenizer.texts_to_sequences(text_corpus_valid)\n",
        "sequences_test = tokenizer.texts_to_sequences(text_corpus_test)\n",
        "\n",
        "word_count = len(tokenizer.index_word) + 1\n",
        "training_length = max([len(i.split()) for i in text_corpus_train])\n",
        "\n",
        "X_train = pad_sequences(sequences_train, maxlen=training_length)\n",
        "X_valid = pad_sequences(sequences_val, maxlen=training_length)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krOAcWTaDhTV"
      },
      "source": [
        "y_train = df_train['class'].values\n",
        "y_val = df_val['class'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ny2PWViHDhTW"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "\n",
        "model.add(SimpleRNN(64))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0MQBD3BPDhTW",
        "outputId": "cc7e2585-4ad3-4fcc-d207-72f57a1e17e2"
      },
      "source": [
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 5s 95ms/step - loss: 0.4181 - accuracy: 0.8598 - val_loss: 0.2171 - val_accuracy: 0.9435\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 3s 79ms/step - loss: 0.2698 - accuracy: 0.9298 - val_loss: 0.2158 - val_accuracy: 0.9435\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 3s 79ms/step - loss: 0.2452 - accuracy: 0.9302 - val_loss: 0.1269 - val_accuracy: 0.9549\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 3s 79ms/step - loss: 0.1401 - accuracy: 0.9507 - val_loss: 0.1373 - val_accuracy: 0.9554\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hqLSX6TyDhTX",
        "outputId": "944ca915-0e0b-47cc-885b-670fbcee184f"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 21ms/step - loss: 0.1548 - accuracy: 0.9496\n",
            "\n",
            "\n",
            "Test score: 0.15477579832077026\n",
            "Test accuracy: 0.9495798349380493\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhJ3L9LsDhTX"
      },
      "source": [
        "# Какие проблемы у рекурентных сетей?\n",
        "\n",
        "- затухают градиенты\n",
        "- медленно, нужно всегда дойти до конца\n",
        "\n",
        "Как решить? -> LSTM\n",
        "\n",
        "\n",
        "<img src=\"images/lstm.png\">\n",
        "\n",
        "\n",
        "https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
        "\n",
        "\n",
        "Давайте, кратко посмотрим как это работает:\n",
        "\n",
        "\n",
        "<img src=\"images/LSTMMaths.png\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsICfj38DhTY",
        "outputId": "6a65499d-5bcb-44a1-e7b1-305fcaf78efc"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(LSTM(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 11s 241ms/step - loss: 0.5390 - accuracy: 0.9008 - val_loss: 0.2359 - val_accuracy: 0.9435\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 8s 229ms/step - loss: 0.2711 - accuracy: 0.9266 - val_loss: 0.2126 - val_accuracy: 0.9435\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 8s 226ms/step - loss: 0.2499 - accuracy: 0.9281 - val_loss: 0.1664 - val_accuracy: 0.9435\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 8s 227ms/step - loss: 0.1566 - accuracy: 0.9364 - val_loss: 0.0990 - val_accuracy: 0.9642\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 8s 226ms/step - loss: 0.0618 - accuracy: 0.9806 - val_loss: 0.1013 - val_accuracy: 0.9642\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umEC69lzDhTZ",
        "outputId": "d5f9f52f-d48f-4c9a-d9b6-ea670e56349a"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 37ms/step - loss: 0.1351 - accuracy: 0.9603\n",
            "\n",
            "\n",
            "Test score: 0.13506671786308289\n",
            "Test accuracy: 0.9603174328804016\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vc99YNpLDhTZ"
      },
      "source": [
        "# Какие проблемы:\n",
        "\n",
        "- вычислительно сложно -> медленнее\n",
        "- на очень длинных последовательностях все равно затухает градиент\n",
        "\n",
        "\n",
        "Зачем платить больше - уберем некоторые врата (точнее совместим) -> ускоримся, уменьшим число параметров -> GRU\n",
        "\n",
        "\n",
        "<img src=\"images/gru.png\">\n",
        "\n",
        "\n",
        "GRU Math\n",
        "\n",
        "\n",
        "<img src=\"images/GRUMath.png\">\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsObd8RLDhTa",
        "outputId": "42d8c578-d0b0-4ebf-a8ae-26c75610eb12"
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(\n",
        "    Embedding(input_dim=word_count,\n",
        "              input_length=training_length,\n",
        "              output_dim=30,\n",
        "              trainable=True,\n",
        "              mask_zero=True))\n",
        "model.add(Masking(mask_value=0.0))\n",
        "model.add(GRU(64, recurrent_dropout=0.2))\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(X_train, y_train,\n",
        "                    batch_size=512,\n",
        "                    epochs=10,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "34/34 [==============================] - 10s 203ms/step - loss: 0.5846 - accuracy: 0.8640 - val_loss: 0.2080 - val_accuracy: 0.9435\n",
            "Epoch 2/10\n",
            "34/34 [==============================] - 6s 188ms/step - loss: 0.2359 - accuracy: 0.9308 - val_loss: 0.1652 - val_accuracy: 0.9471\n",
            "Epoch 3/10\n",
            "34/34 [==============================] - 6s 190ms/step - loss: 0.1605 - accuracy: 0.9368 - val_loss: 0.1098 - val_accuracy: 0.9601\n",
            "Epoch 4/10\n",
            "34/34 [==============================] - 6s 189ms/step - loss: 0.0634 - accuracy: 0.9776 - val_loss: 0.1072 - val_accuracy: 0.9606\n",
            "Epoch 5/10\n",
            "34/34 [==============================] - 6s 190ms/step - loss: 0.0249 - accuracy: 0.9924 - val_loss: 0.1238 - val_accuracy: 0.9637\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOZEXeRyDhTa",
        "outputId": "168e1558-80ad-45d4-e3d3-205c6f1d2797"
      },
      "source": [
        "score = model.evaluate(X_valid, y_val, batch_size=512, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 34ms/step - loss: 0.1687 - accuracy: 0.9566\n",
            "\n",
            "\n",
            "Test score: 0.1686669886112213\n",
            "Test accuracy: 0.9565826058387756\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rs6F1lb0JGD7"
      },
      "source": [
        "train_corpus = \" \".join(df_train[\"text\"])\n",
        "train_corpus = train_corpus.lower()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yLhCbE5xI4uB",
        "outputId": "ecec85af-3331-4a80-d7f0-8d1b8cd0a707"
      },
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download(\"punkt\")\n",
        "\n",
        "tokens = word_tokenize(train_corpus)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOGLANZmJMSX"
      },
      "source": [
        "max_words = 1000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYhQqSLCJJtU"
      },
      "source": [
        "from nltk.probability import FreqDist\n",
        "dist = FreqDist(tokens_filtered)\n",
        "tokens_filtered_top = [pair[0] for pair in dist.most_common(max_words-1)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guUV3fDAJQR0"
      },
      "source": [
        "vocabulary = {v: k for k, v in dict(enumerate(tokens_filtered_top, 1)).items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eVfQwvRPJRdv"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def text_to_sequence(text, maxlen):\n",
        "    result = []\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    tokens_filtered = [word for word in tokens if word.isalnum()]\n",
        "    for word in tokens_filtered:\n",
        "        if word in vocabulary:\n",
        "            result.append(vocabulary[word])\n",
        "    padding = [0]*(maxlen-len(result))\n",
        "    return padding + result[-maxlen:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8jOiqEFJUZ5"
      },
      "source": [
        "max_len = 50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk9NRXzdJSxe"
      },
      "source": [
        "x_train = np.asarray([text_to_sequence(text, max_len) for text in df_train[\"text\"]], dtype=np.int32)\n",
        "x_test = np.asarray([text_to_sequence(text, max_len) for text in df_test[\"text\"]], dtype=np.int32)\n",
        "x_val = np.asarray([text_to_sequence(text, max_len) for text in df_val[\"text\"]], dtype=np.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgjYMiwFJX8-"
      },
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Dense, Dropout, Activation, Input, Embedding, Conv1D, GlobalMaxPool1D\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import TensorBoard \n",
        "from keras.objectives import categorical_crossentropy\n",
        "from keras.callbacks import EarlyStopping  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "luOlHIb-JZA0"
      },
      "source": [
        "num_classes = 2\n",
        "y_train = keras.utils.to_categorical(df_train['class'], num_classes)\n",
        "y_val = keras.utils.to_categorical(df_val['class'], num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ft10jI7bJcxT"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=max_words, output_dim=256, input_length=max_len))\n",
        "model.add(Conv1D(256, 3))\n",
        "model.add(Conv1D(128, 3))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(GlobalMaxPool1D())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8lPRM7GDJd3q"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FB1XUdd0JgXk"
      },
      "source": [
        "batch_size = 256\n",
        "epochs = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2Whkgu8Je7E",
        "outputId": "b29b2c14-9fbf-43b5-a393-dac4351188c3"
      },
      "source": [
        "tensorboard=TensorBoard(log_dir='./logs', write_graph=True, write_images=True)\n",
        "early_stopping=EarlyStopping(monitor='val_loss')  \n",
        "\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_split=0.1,\n",
        "                    callbacks=[tensorboard, early_stopping])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "68/68 [==============================] - 43s 624ms/step - loss: 0.3086 - accuracy: 0.9188 - val_loss: 0.1278 - val_accuracy: 0.9544\n",
            "Epoch 2/10\n",
            "68/68 [==============================] - 42s 620ms/step - loss: 0.1514 - accuracy: 0.9451 - val_loss: 0.1195 - val_accuracy: 0.9570\n",
            "Epoch 3/10\n",
            "68/68 [==============================] - 43s 626ms/step - loss: 0.1125 - accuracy: 0.9578 - val_loss: 0.1296 - val_accuracy: 0.9497\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63SCHWC8Jpup",
        "outputId": "e19e19ea-b166-4cb8-dc05-a150cffc1fd6"
      },
      "source": [
        "score = model.evaluate(x_val, y_val, batch_size=batch_size, verbose=1)\n",
        "print('\\n')\n",
        "print('Test score:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9/9 [==============================] - 1s 117ms/step - loss: 0.1599 - accuracy: 0.9435\n",
            "\n",
            "\n",
            "Test score: 0.1599329710006714\n",
            "Test accuracy: 0.9435107111930847\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuznI0AFJq5Z"
      },
      "source": [
        "# Выводы\n",
        "\n",
        "На текущих данных получается, что свёрточная не хуже рекурретнтной. \n",
        "Я использовал данные по твитам из первой домашки. Эти данные нек загрузились.\n",
        "\n",
        "Думаю, что детальная настройка параметров позволит в итоге добиться лучших результатов, однако это требует даже  на таком датасете времени.\n",
        "\n",
        "Кстати, почему мы не переносим вычисления на gpu?"
      ]
    }
  ]
}